# 安全数据处理说明文档

## 🛡️ 解决的问题

### 之前的隐患
1. **数据截断**: 强制截断超出目标维度的数据，丢失重要信息
2. **强制维度统一**: 不同本体的数据被强制统一到相同维度，破坏物理意义
3. **零值填充**: 用0填充缺失维度，引入虚假信息
4. **数据混淆**: 不同本体的关节数据被混合处理，失去物理含义

### 新的安全方案
1. **分别处理**: 每个本体独立处理，避免数据混淆
2. **保持原始维度**: 不强制修改数据维度，保持物理意义
3. **数据完整性**: 所有数据都被完整保留，无截断或填充
4. **物理意义保护**: 关节顺序和含义完全保持

## 📁 输出文件结构

运行 `bash process_data.sh stack_blocks_three demo_clean 200` 后，会生成：

```
./data/
├── stack_blocks_three-demo_clean-aloha-agilex-50.zarr/     # aloha-agilex的50个episode
├── stack_blocks_three-demo_clean-franka-panda-50.zarr/     # franka-panda的50个episode
├── stack_blocks_three-demo_clean-ARX-X5-50.zarr/          # ARX-X5的50个episode
└── stack_blocks_three-demo_clean-ur5-wsg-50.zarr/         # ur5-wsg的50个episode
```

## 🔧 数据处理流程

### 第一遍：收集episode信息
- 扫描所有episode，按本体类型分组
- 验证每个本体的数据一致性
- 检查维度、长度等关键参数

### 第二遍：分别处理每个本体
- 为每个本体创建独立的zarr文件
- 保持原始数据维度和结构
- 记录详细的数据统计信息

## 📊 数据验证

### 维度一致性检查
- 检查同一本体内所有episode的维度是否一致
- 验证左臂、右臂、夹爪的维度
- 检查episode长度的一致性

### 数据完整性验证
- 确保所有数据都被完整保留
- 验证数据类型的正确性
- 检查数值范围的合理性

## ⚠️ 重要注意事项

### 训练策略建议
1. **分别训练**: 为每个本体创建单独的模型
2. **动态输入**: 使用动态输入层处理不同维度
3. **避免混合**: 不要混合训练不同本体的数据

### 数据使用建议
1. **保持分离**: 不同本体的数据文件保持分离
2. **维度匹配**: 确保模型输入维度与数据维度匹配
3. **物理意义**: 理解每个维度的物理含义

## 🚀 使用方法

### 基本命令
```bash
cd /home/shengbang/RoboTwin/policy/DP
bash process_data.sh stack_blocks_three demo_clean 200
```

### 输出说明
- 每个本体会生成独立的zarr文件
- 文件名包含本体类型和episode数量
- 数据完全保持原始格式和维度

### 验证输出
程序会显示详细的处理信息：
- 每个本体的数据统计
- 维度一致性检查结果
- 重要注意事项和建议

## 🔍 故障排除

### 常见问题
1. **配置文件缺失**: 检查 `_embodiment_config.yml` 是否存在
2. **数据文件损坏**: 跳过损坏的episode，继续处理其他数据
3. **维度不一致**: 检查同一本体的数据是否来自相同配置

### 调试信息
程序提供详细的调试信息：
- 每个episode的处理状态
- 数据维度和形状信息
- 错误和警告信息

## 📈 性能优化

### 内存使用
- 分别处理减少内存占用
- 避免大数组的强制转换
- 及时释放不需要的数据

### 处理速度
- 并行处理不同本体（未来优化）
- 减少不必要的数据复制
- 优化文件I/O操作

## 🔮 未来改进

### 计划功能
1. **并行处理**: 同时处理多个本体
2. **增量更新**: 支持增量数据更新
3. **自动验证**: 更智能的数据验证
4. **配置优化**: 自动优化处理参数

### 用户反馈
欢迎提供使用反馈和改进建议！
