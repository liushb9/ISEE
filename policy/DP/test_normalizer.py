#!/usr/bin/env python3
"""
æµ‹è¯•ä¼˜åŒ–åçš„å½’ä¸€åŒ–å‡½æ•°
éªŒè¯å†…å­˜ä½¿ç”¨å’Œå½’ä¸€åŒ–æ•ˆæœ
"""

import numpy as np
import sys
import os

# æ·»åŠ è·¯å¾„
sys.path.append('/home/shengbang/RoboTwin/policy/DP')

from diffusion_policy.dataset.robot_image_dataset import RobotImageDataset

def test_normalizer_memory_usage():
    """æµ‹è¯•å½’ä¸€åŒ–å‡½æ•°çš„å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    print("=== æµ‹è¯•å½’ä¸€åŒ–å‡½æ•°å†…å­˜ä½¿ç”¨ ===")
    
    # æ¨¡æ‹Ÿæ•°æ®é›†è·¯å¾„ï¼ˆéœ€è¦æ›¿æ¢ä¸ºå®é™…è·¯å¾„ï¼‰
    zarr_path = "data/six-tasks.zarr"  # æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
    
    if not os.path.exists(zarr_path):
        print(f"âŒ æ•°æ®é›†ä¸å­˜åœ¨: {zarr_path}")
        print("è¯·å…ˆè¿è¡Œæ•°æ®å¤„ç†è„šæœ¬åˆ›å»ºæ•°æ®é›†")
        return
    
    try:
        # åˆ›å»ºæ•°æ®é›†å®ä¾‹
        print("ğŸ“Š åˆ›å»ºæ•°æ®é›†å®ä¾‹...")
        dataset = RobotImageDataset(
            zarr_path=zarr_path,
            horizon=1,
            pad_before=0,
            pad_after=0,
            seed=42,
            val_ratio=0.0,
            batch_size=128,
            max_train_episodes=None,
        )
        
        print(f"âœ… æ•°æ®é›†åˆ›å»ºæˆåŠŸ")
        print(f"   - æ€»episodes: {dataset.replay_buffer.n_episodes}")
        print(f"   - Actionç»´åº¦: {dataset.replay_buffer['action'].shape[1]}")
        print(f"   - Stateç»´åº¦: {dataset.replay_buffer['state'].shape[1]}")
        
        # æµ‹è¯•å½’ä¸€åŒ–å‡½æ•°
        print("\nğŸ”§ æµ‹è¯•å½’ä¸€åŒ–å‡½æ•°...")
        import psutil
        import gc
        
        # è®°å½•å†…å­˜ä½¿ç”¨
        process = psutil.Process()
        mem_before = process.memory_info().rss / 1024 / 1024  # MB
        print(f"   å†…å­˜ä½¿ç”¨å‰: {mem_before:.2f} MB")
        
        # è¿è¡Œå½’ä¸€åŒ–
        normalizer = dataset.get_normalizer()
        
        # æ¸…ç†å†…å­˜
        gc.collect()
        mem_after = process.memory_info().rss / 1024 / 1024  # MB
        print(f"   å†…å­˜ä½¿ç”¨å: {mem_after:.2f} MB")
        print(f"   å†…å­˜å¢é•¿: {mem_after - mem_before:.2f} MB")
        
        # æ£€æŸ¥å½’ä¸€åŒ–å™¨
        print(f"\nğŸ“‹ å½’ä¸€åŒ–å™¨ä¿¡æ¯:")
        print(f"   - Actionå½’ä¸€åŒ–å™¨: {type(normalizer['action'])}")
        
        if hasattr(normalizer['action'], 'params_dict'):
            params = normalizer['action'].params_dict
            print(f"   - Scale shape: {params['scale'].shape}")
            print(f"   - Offset shape: {params['offset'].shape}")
            
            # æ£€æŸ¥å‰3ç»´ï¼ˆä½ç½®ï¼‰æ˜¯å¦è¢«å½’ä¸€åŒ–
            pos_scale = params['scale'][:3]
            pos_offset = params['offset'][:3]
            print(f"   - ä½ç½®å½’ä¸€åŒ–å‚æ•°:")
            print(f"     Scale: {pos_scale}")
            print(f"     Offset: {pos_offset}")
            
            # æ£€æŸ¥ä¸­é—´6ç»´ï¼ˆæ—‹è½¬ï¼‰æ˜¯å¦ä¿æŒä¸å˜
            rot_scale = params['scale'][3:9]
            rot_offset = params['offset'][3:9]
            print(f"   - æ—‹è½¬å½’ä¸€åŒ–å‚æ•°:")
            print(f"     Scale: {rot_scale}")
            print(f"     Offset: {rot_offset}")
            
            # æ£€æŸ¥æœ€å1ç»´ï¼ˆå¤¹çˆªï¼‰æ˜¯å¦ä¿æŒä¸å˜
            gripper_scale = params['scale'][9:]
            gripper_offset = params['offset'][9:]
            print(f"   - å¤¹çˆªå½’ä¸€åŒ–å‚æ•°:")
            print(f"     Scale: {gripper_scale}")
            print(f"     Offset: {gripper_offset}")
        
        print("\nâœ… å½’ä¸€åŒ–æµ‹è¯•å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_normalizer_memory_usage()
