#!/bin/bash

# å¤šå¡è®­ç»ƒå¯åŠ¨è„šæœ¬
# ä½¿ç”¨æ–¹æ³•: bash train_multi_gpu.sh [ä»»åŠ¡å] [é…ç½®] [æ•°æ®é‡] [ç§å­] [GPUæ•°é‡] [GPU_IDs]
# ä¾‹å¦‚: bash train_multi_gpu.sh six_tasks demo_clean 1200 0 3 "0,2,4"

task_name=${1:-"six_tasks"}
task_config=${2:-"demo_clean"}
expert_data_num=${3:-1200}
seed=${4:-0}
num_gpus=${5:-2}  # é»˜è®¤ä½¿ç”¨2å¼ GPU
gpu_ids=${6:-""}  # æ–°å¢ï¼šæŒ‡å®šå…·ä½“çš„GPU IDï¼Œä¾‹å¦‚ "0,2,4"

head_camera_type=D435
DEBUG=False
save_ckpt=True

echo "=== å¤šå¡è®­ç»ƒé…ç½® ==="
echo "ä»»åŠ¡åç§°: ${task_name}"
echo "ä»»åŠ¡é…ç½®: ${task_config}"
echo "æ•°æ®æ•°é‡: ${expert_data_num}"
echo "éšæœºç§å­: ${seed}"
echo "GPUæ•°é‡: ${num_gpus}"
if [ ! -z "$gpu_ids" ]; then
    echo "æŒ‡å®šGPU ID: ${gpu_ids}"
fi
echo "=================="

# æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å­˜åœ¨
if [ "$task_name" = "six_tasks" ]; then
    # æ£€æŸ¥ä¸¤ç§å¯èƒ½çš„è·¯å¾„ï¼šè¿å­—ç¬¦å’Œä¸‹åˆ’çº¿
    if [ -d "./data/six-tasks.zarr" ]; then
        echo "âœ… æ‰¾åˆ°æ•°æ®é›†: ./data/six-tasks.zarr"
        dataset_path="./data/six-tasks.zarr"
    elif [ -d "./data/six_tasks.zarr" ]; then
        echo "âœ… æ‰¾åˆ°æ•°æ®é›†: ./data/six_tasks.zarr"
        dataset_path="./data/six_tasks.zarr"
    else
        echo "âŒ six_tasks.zarræ•°æ®é›†æœªæ‰¾åˆ°ï¼"
        echo "è¯·æ£€æŸ¥ä»¥ä¸‹è·¯å¾„ï¼š"
        echo "  - ./data/six-tasks.zarr"
        echo "  - ./data/six_tasks.zarr"
        echo "è¯·å…ˆè¿è¡Œ: python merge_zarr.py"
        exit 1
    fi
fi

# æ£€æµ‹å¯ç”¨çš„GPUæ•°é‡
available_gpus=$(nvidia-smi --list-gpus | wc -l)
echo "ç³»ç»Ÿå¯ç”¨GPUæ•°é‡: ${available_gpus}"

# å¦‚æœæŒ‡å®šäº†GPU IDï¼ŒéªŒè¯å…¶æœ‰æ•ˆæ€§
if [ ! -z "$gpu_ids" ]; then
    # è§£æGPU IDåˆ—è¡¨
    IFS=',' read -ra gpu_array <<< "$gpu_ids"
    specified_gpu_count=${#gpu_array[@]}
    
    echo "æŒ‡å®šçš„GPU ID: ${gpu_ids}"
    echo "æŒ‡å®šGPUæ•°é‡: ${specified_gpu_count}"
    
    # éªŒè¯æŒ‡å®šçš„GPU IDæ˜¯å¦æœ‰æ•ˆ
    for gpu_id in "${gpu_array[@]}"; do
        if [ "$gpu_id" -ge "$available_gpus" ] || [ "$gpu_id" -lt 0 ]; then
            echo "âŒ é”™è¯¯: GPU ID ${gpu_id} è¶…å‡ºèŒƒå›´ [0, $((available_gpus-1))]"
            exit 1
        fi
    done
    
    # æ›´æ–°GPUæ•°é‡ä¸ºå®é™…æŒ‡å®šçš„æ•°é‡
    num_gpus=$specified_gpu_count
    echo "âœ… ä½¿ç”¨æŒ‡å®šçš„ ${num_gpus} å¼ GPU: ${gpu_ids}"
else
    # æ²¡æœ‰æŒ‡å®šGPU IDï¼Œä½¿ç”¨é»˜è®¤é€»è¾‘
    if [ $num_gpus -gt $available_gpus ]; then
        echo "âš ï¸  è¯·æ±‚çš„GPUæ•°é‡ (${num_gpus}) è¶…è¿‡å¯ç”¨æ•°é‡ (${available_gpus})"
        echo "å°†ä½¿ç”¨æ‰€æœ‰å¯ç”¨GPU: ${available_gpus}"
        num_gpus=$available_gpus
        # ç”Ÿæˆè¿ç»­çš„GPU IDåˆ—è¡¨
        gpu_ids=$(seq -s, 0 $((available_gpus-1)))
    else
        # ç”Ÿæˆè¿ç»­çš„GPU IDåˆ—è¡¨
        gpu_ids=$(seq -s, 0 $((num_gpus-1)))
    fi
fi

# æ£€æµ‹æ•°æ®ç»´åº¦
if [ "$task_name" = "six_tasks" ]; then
    echo "ğŸ” æ£€æµ‹æ•°æ®é›†ç»´åº¦..."
    actual_dim=$(python -c "
import zarr
import numpy as np
try:
    # å°è¯•è¿å­—ç¬¦è·¯å¾„
    root = zarr.open('./data/six-tasks.zarr', mode='r')
    if 'data' in root and 'action' in root['data']:
        action_shape = root['data']['action'].shape
        if len(action_shape) >= 2:
            print(action_shape[1])
        else:
            print('10')
    else:
        print('10')
except Exception as e:
    try:
        # å°è¯•ä¸‹åˆ’çº¿è·¯å¾„
        root = zarr.open('./data/six_tasks.zarr', mode='r')
        if 'data' in root and 'action' in root['data']:
            action_shape = root['data']['action'].shape
            if len(action_shape) >= 2:
                print(action_shape[1])
            else:
                print('10')
        else:
            print('10')
    except Exception as e2:
        print(f'Error: {e2}')
        print('10')
")

    echo "æ£€æµ‹åˆ°actionç»´åº¦: ${actual_dim}"

    # æ ¹æ®ç»´åº¦é€‰æ‹©é…ç½®
    if [ "$actual_dim" = "10" ]; then
        action_dim=10
        config_name="robot_dp_10"
        echo "âœ… ä½¿ç”¨10ç»´é…ç½® (endposeæ ¼å¼)"
    elif [ "$actual_dim" = "14" ]; then
        action_dim=14
        config_name="robot_dp_14"
        echo "âš ï¸  ä½¿ç”¨14ç»´é…ç½® (åŸå§‹å…³èŠ‚æ•°æ®)"
    elif [ "$actual_dim" = "16" ]; then
        action_dim=16
        config_name="robot_dp_16"
        echo "âš ï¸  ä½¿ç”¨16ç»´é…ç½® (åŸå§‹å…³èŠ‚æ•°æ®)"
    else
        action_dim=10
        config_name="robot_dp_10"
        echo "âš ï¸  æœªçŸ¥ç»´åº¦ï¼Œä½¿ç”¨é»˜è®¤10ç»´é…ç½®"
    fi
else
    # å¯¹äºå…¶ä»–ä»»åŠ¡ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
    action_dim=14
    config_name="robot_dp_14"
fi

exp_name=${task_name}-robot_dp-train
run_dir="data/outputs/${exp_name}_seed${seed}"

echo -e "\033[33m=== è®­ç»ƒé…ç½® ==="
echo -e "\033[33mä»»åŠ¡åç§°: ${task_name}\033[0m"
echo -e "\033[33mé…ç½®åç§°: ${config_name}\033[0m"
echo -e "\033[33mActionç»´åº¦: ${action_dim}\033[0m"
echo -e "\033[33mGPUæ•°é‡: ${num_gpus}\033[0m"
echo -e "\033[33mä½¿ç”¨GPU ID: ${gpu_ids}\033[0m"
echo -e "\033[33mæ•°æ®é›†è·¯å¾„: data/${task_name}-${task_config}-${expert_data_num}.zarr\033[0m"

if [ $DEBUG = True ]; then
    wandb_mode=offline
    echo -e "\033[33mDebug mode!\033[0m"
else
    wandb_mode=online
    echo -e "\033[33mTrain mode\033[0m"
fi

export HYDRA_FULL_ERROR=1 
export CUDA_VISIBLE_DEVICES=${gpu_ids}

echo -e "\033[32må¼€å§‹å¤šå¡è®­ç»ƒ...\033[0m"
echo -e "\033[32mä½¿ç”¨GPU: ${CUDA_VISIBLE_DEVICES}\033[0m"
echo -e "\033[32må®é™…GPUæ•°é‡: ${num_gpus}\033[0m"

# å¯åŠ¨å¤šå¡è®­ç»ƒ
python train.py --config-name=${config_name}.yaml \
                        task.name=${task_name} \
                        +task.dataset.zarr_path="${dataset_path}" \
                        training.debug=$DEBUG \
                        training.seed=${seed} \
                        training.device="cuda:0" \
                        exp_name=${exp_name} \
                        logging.mode=${wandb_mode} \
                        setting=${task_config} \
                        expert_data_num=${expert_data_num} \
                        head_camera_type=$head_camera_type

echo -e "\033[32må¤šå¡è®­ç»ƒå®Œæˆï¼\033[0m"
