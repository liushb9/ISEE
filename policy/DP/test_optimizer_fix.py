#!/usr/bin/env python3
"""
æµ‹è¯•ä¼˜åŒ–å™¨ä¿®å¤
éªŒè¯AdamWä¼˜åŒ–å™¨çš„åˆ›å»º
"""

import sys
import os

# è®¾ç½®æ­£ç¡®çš„Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

def test_optimizer_creation():
    """æµ‹è¯•ä¼˜åŒ–å™¨åˆ›å»º"""
    print("=== æµ‹è¯•ä¼˜åŒ–å™¨åˆ›å»º ===")
    
    try:
        # æµ‹è¯•å¯¼å…¥
        import torch
        import torch.nn as nn
        from omegaconf import OmegaConf
        
        # åˆ›å»ºç®€å•æ¨¡å‹
        class SimpleModel(nn.Module):
            def __init__(self):
                super().__init__()
                self.linear = nn.Linear(10, 1)
            
            def forward(self, x):
                return self.linear(x)
        
        model = SimpleModel()
        print("âœ… ç®€å•æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºä¼˜åŒ–å™¨é…ç½®
        optimizer_config = {
            '_target_': 'torch.optim.AdamW',
            'lr': 1e-4,
            'betas': [0.95, 0.999],
            'eps': 1e-8,
            'weight_decay': 1e-6
        }
        
        cfg = OmegaConf.create(optimizer_config)
        print("âœ… ä¼˜åŒ–å™¨é…ç½®åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•Hydraå®ä¾‹åŒ–
        import hydra
        optimizer = hydra.utils.instantiate(cfg, params=model.parameters())
        print("âœ… ä¼˜åŒ–å™¨é€šè¿‡Hydraåˆ›å»ºæˆåŠŸ")
        print(f"   ä¼˜åŒ–å™¨ç±»å‹: {type(optimizer)}")
        print(f"   å‚æ•°æ•°é‡: {len(list(optimizer.param_groups))}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ä¼˜åŒ–å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_workspace_optimizer():
    """æµ‹è¯•Workspaceä¸­çš„ä¼˜åŒ–å™¨"""
    print("\n=== æµ‹è¯•Workspaceä¼˜åŒ–å™¨ ===")
    
    try:
        # æµ‹è¯•å¯¼å…¥
        from diffusion_policy.workspace.robotworkspace import RobotWorkspace
        print("âœ… RobotWorkspaceå¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•é…ç½®ç»“æ„
        import yaml
        from omegaconf import OmegaConf
        
        # åˆ›å»ºæœ€å°é…ç½®
        config = {
            'policy': {
                '_target_': 'diffusion_policy.policy.diffusion_unet_image_policy.DiffusionUnetImagePolicy',
                'shape_meta': {
                    'obs': {'head_cam': {'shape': [3, 256, 256], 'type': 'rgb'}},
                    'action': {'shape': [10], 'type': 'low_dim'}
                },
                'horizon': 8,
                'n_action_steps': 6,
                'n_obs_steps': 3
            },
            'training': {
                'use_ema': True,
                'seed': 42,
                'device': 'cpu'
            },
            'optimizer': {
                '_target_': 'torch.optim.AdamW',
                'lr': 1e-4,
                'betas': [0.95, 0.999],
                'eps': 1e-8,
                'weight_decay': 1e-6
            },
            'task': {
                'dataset': {
                    '_target_': 'diffusion_policy.dataset.robot_image_dataset.RobotImageDataset',
                    'zarr_path': None
                }
            }
        }
        
        cfg = OmegaConf.create(config)
        print("âœ… é…ç½®åˆ›å»ºæˆåŠŸ")
        print(f"   ä¼˜åŒ–å™¨é…ç½®: {cfg.optimizer}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Workspaceä¼˜åŒ–å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("=== ä¼˜åŒ–å™¨ä¿®å¤æµ‹è¯• ===")
    
    # æµ‹è¯•1: ä¼˜åŒ–å™¨åˆ›å»º
    optimizer_ok = test_optimizer_creation()
    
    # æµ‹è¯•2: Workspaceä¼˜åŒ–å™¨
    workspace_ok = test_workspace_optimizer()
    
    # æ€»ç»“
    print(f"\n=== æµ‹è¯•æ€»ç»“ ===")
    print(f"ä¼˜åŒ–å™¨åˆ›å»º: {'âœ…' if optimizer_ok else 'âŒ'}")
    print(f"Workspaceä¼˜åŒ–å™¨: {'âœ…' if workspace_ok else 'âŒ'}")
    
    if optimizer_ok and workspace_ok:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ä¼˜åŒ–å™¨ä¿®å¤æˆåŠŸ")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥")

if __name__ == "__main__":
    main()
