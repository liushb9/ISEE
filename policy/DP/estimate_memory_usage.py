#!/usr/bin/env python3
"""
å¤šå¡è®­ç»ƒå†…å­˜ä½¿ç”¨ä¼°ç®—è„šæœ¬
åŸºäºä½ çš„æœåŠ¡å™¨é…ç½®å’Œè®­ç»ƒå‚æ•°è¿›è¡Œä¼°ç®—
"""

import os
import sys
import json
import subprocess
from pathlib import Path

def get_gpu_info():
    """è·å–GPUä¿¡æ¯"""
    try:
        result = subprocess.run(['nvidia-smi', '--query-gpu=memory.total,memory.used,memory.free', '--format=csv,noheader,nounits'], 
                              capture_output=True, text=True)
        gpu_info = []
        for line in result.stdout.strip().split('\n'):
            if line:
                total, used, free = map(int, line.split(', '))
                gpu_info.append({
                    'total': total,
                    'used': used,
                    'free': free
                })
        return gpu_info
    except Exception as e:
        print(f"âš ï¸  æ— æ³•è·å–GPUä¿¡æ¯: {e}")
        return None

def estimate_dataset_size(zarr_path):
    """ä¼°ç®—æ•°æ®é›†å¤§å°"""
    if not os.path.exists(zarr_path):
        print(f"âŒ æ•°æ®é›†ä¸å­˜åœ¨: {zarr_path}")
        return None
    
    try:
        # ä½¿ç”¨zarrè·å–æ•°æ®é›†ä¿¡æ¯
        import zarr
        store = zarr.open(zarr_path, mode='r')
        
        total_size = 0
        dataset_info = {}
        
        for key, arr in store.items():
            if hasattr(arr, 'shape') and hasattr(arr, 'dtype'):
                # è®¡ç®—æ•°ç»„å¤§å°
                array_size = arr.nbytes / (1024**3)  # GB
                total_size += array_size
                dataset_info[key] = {
                    'shape': arr.shape,
                    'dtype': str(arr.dtype),
                    'size_gb': array_size
                }
        
        return {
            'total_size_gb': total_size,
            'details': dataset_info
        }
    except Exception as e:
        print(f"âš ï¸  æ— æ³•è¯»å–æ•°æ®é›†ä¿¡æ¯: {e}")
        return None

def estimate_training_memory(dataset_size_gb, num_gpus, batch_size, sequence_length, action_dim=10):
    """ä¼°ç®—è®­ç»ƒå†…å­˜éœ€æ±‚"""
    
    # åŸºç¡€å†…å­˜éœ€æ±‚ï¼ˆGBï¼‰
    base_memory = {
        'model_weights': 2.0,        # æ¨¡å‹æƒé‡
        'optimizer_states': 4.0,     # ä¼˜åŒ–å™¨çŠ¶æ€
        'gradients': 2.0,            # æ¢¯åº¦
        'activations': 1.0,          # æ¿€æ´»å€¼
        'system_overhead': 0.5       # ç³»ç»Ÿå¼€é”€
    }
    
    # æ•°æ®ç›¸å…³å†…å­˜
    data_memory = {
        'batch_data': (batch_size * sequence_length * action_dim * 4) / (1024**3),  # float32
        'cached_data': dataset_size_gb * 0.1,  # å‡è®¾ç¼“å­˜10%çš„æ•°æ®
    }
    
    # å¤šå¡è®­ç»ƒé¢å¤–å¼€é”€
    ddp_overhead = {
        'gradient_sync': 0.5,        # æ¢¯åº¦åŒæ­¥
        'communication': 0.3,        # è¿›ç¨‹é—´é€šä¿¡
        'redundant_storage': 0.2     # é‡å¤å­˜å‚¨
    }
    
    # è®¡ç®—æ€»å†…å­˜
    total_base = sum(base_memory.values())
    total_data = sum(data_memory.values())
    total_ddp = sum(ddp_overhead.values()) * num_gpus
    
    total_memory = total_base + total_data + total_ddp
    
    return {
        'base_memory': base_memory,
        'data_memory': data_memory,
        'ddp_overhead': ddp_overhead,
        'total_memory': total_memory,
        'per_gpu_memory': total_memory / num_gpus
    }

def check_available_resources(gpu_ids, required_memory_per_gpu):
    """æ£€æŸ¥å¯ç”¨èµ„æº"""
    gpu_info = get_gpu_info()
    if not gpu_info:
        return None
    
    available_gpus = []
    total_free_memory = 0
    
    for gpu_id in gpu_ids:
        if gpu_id < len(gpu_info):
            gpu = gpu_info[gpu_id]
            free_gb = gpu['free'] / 1024  # è½¬æ¢ä¸ºGB
            
            if free_gb >= required_memory_per_gpu:
                available_gpus.append({
                    'id': gpu_id,
                    'free_gb': free_gb,
                    'status': 'âœ… å¯ç”¨'
                })
                total_free_memory += free_gb
            else:
                available_gpus.append({
                    'id': gpu_id,
                    'free_gb': free_gb,
                    'status': f'âŒ æ˜¾å­˜ä¸è¶³ (éœ€è¦{required_memory_per_gpu:.1f}GB, å¯ç”¨{free_gb:.1f}GB)'
                })
    
    return {
        'gpus': available_gpus,
        'total_free_memory': total_free_memory,
        'can_run': all(gpu['status'].startswith('âœ…') for gpu in available_gpus)
    }

def main():
    """ä¸»å‡½æ•°"""
    print("=== å¤šå¡è®­ç»ƒå†…å­˜éœ€æ±‚ä¼°ç®— ===")
    
    # è®­ç»ƒå‚æ•°
    task_name = "six_tasks"
    config_name = "demo_clean"
    num_episodes = 1200
    seed = 0
    num_gpus = 3
    gpu_ids = [0, 1, 2]
    batch_size = 128  # é»˜è®¤batch size
    sequence_length = 1  # é»˜è®¤åºåˆ—é•¿åº¦
    
    print(f"ğŸ“‹ è®­ç»ƒé…ç½®:")
    print(f"   ä»»åŠ¡åç§°: {task_name}")
    print(f"   é…ç½®åç§°: {config_name}")
    print(f"   Episodeæ•°é‡: {num_episodes}")
    print(f"   GPUæ•°é‡: {num_gpus}")
    print(f"   GPU ID: {gpu_ids}")
    print(f"   Batch Size: {batch_size}")
    print(f"   åºåˆ—é•¿åº¦: {sequence_length}")
    
    # æ£€æŸ¥æ•°æ®é›†
    print(f"\nğŸ“Š æ£€æŸ¥æ•°æ®é›†...")
    dataset_paths = [
        "data/six-tasks.zarr",
        "data/six_tasks-demo_clean-1200.zarr"
    ]
    
    dataset_info = None
    for path in dataset_paths:
        if os.path.exists(path):
            print(f"âœ… æ‰¾åˆ°æ•°æ®é›†: {path}")
            dataset_info = estimate_dataset_size(path)
            break
    
    if not dataset_info:
        print("âŒ æœªæ‰¾åˆ°æ•°æ®é›†ï¼Œä½¿ç”¨é»˜è®¤ä¼°ç®—")
        dataset_info = {'total_size_gb': 50.0, 'details': {}}  # é»˜è®¤50GB
    
    print(f"   æ•°æ®é›†å¤§å°: {dataset_info['total_size_gb']:.2f} GB")
    
    # ä¼°ç®—å†…å­˜éœ€æ±‚
    print(f"\nğŸ§® ä¼°ç®—å†…å­˜éœ€æ±‚...")
    memory_estimate = estimate_training_memory(
        dataset_size_gb=dataset_info['total_size_gb'],
        num_gpus=num_gpus,
        batch_size=batch_size,
        sequence_length=sequence_length
    )
    
    print(f"ğŸ“Š å†…å­˜éœ€æ±‚è¯¦æƒ…:")
    print(f"   åŸºç¡€å†…å­˜:")
    for key, value in memory_estimate['base_memory'].items():
        print(f"     {key}: {value:.1f} GB")
    
    print(f"   æ•°æ®å†…å­˜:")
    for key, value in memory_estimate['data_memory'].items():
        print(f"     {key}: {value:.1f} GB")
    
    print(f"   å¤šå¡å¼€é”€:")
    for key, value in memory_estimate['ddp_overhead'].items():
        print(f"     {key}: {value:.1f} GB Ã— {num_gpus} = {value * num_gpus:.1f} GB")
    
    print(f"\nğŸ’¾ æ€»å†…å­˜éœ€æ±‚:")
    print(f"   æ€»å†…å­˜: {memory_estimate['total_memory']:.1f} GB")
    print(f"   æ¯GPUå†…å­˜: {memory_estimate['per_gpu_memory']:.1f} GB")
    
    # æ£€æŸ¥å¯ç”¨èµ„æº
    print(f"\nğŸ” æ£€æŸ¥å¯ç”¨èµ„æº...")
    resource_check = check_available_resources(gpu_ids, memory_estimate['per_gpu_memory'])
    
    if resource_check:
        print(f"GPUçŠ¶æ€:")
        for gpu in resource_check['gpus']:
            print(f"   GPU {gpu['id']}: {gpu['status']} (å¯ç”¨æ˜¾å­˜: {gpu['free_gb']:.1f} GB)")
        
        print(f"\næ€»å¯ç”¨æ˜¾å­˜: {resource_check['total_free_memory']:.1f} GB")
        
        if resource_check['can_run']:
            print(f"\nâœ… èµ„æºå……è¶³ï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒ!")
            print(f"   å»ºè®®:")
            print(f"   - ç›‘æ§GPUæ˜¾å­˜ä½¿ç”¨: watch -n 1 nvidia-smi")
            print(f"   - å¦‚æœæ˜¾å­˜ä¸è¶³ï¼Œå¯ä»¥å‡å°batch_size")
            print(f"   - ä½¿ç”¨gradient checkpointingèŠ‚çœæ˜¾å­˜")
        else:
            print(f"\nâŒ èµ„æºä¸è¶³ï¼Œæ— æ³•å¼€å§‹è®­ç»ƒ!")
            print(f"   å»ºè®®:")
            print(f"   - å‡å°‘GPUæ•°é‡")
            print(f"   - å‡å°batch_size")
            print(f"   - ç­‰å¾…å…¶ä»–è¿›ç¨‹é‡Šæ”¾GPU")
    else:
        print(f"âš ï¸  æ— æ³•æ£€æŸ¥GPUçŠ¶æ€")
    
    # ä¿å­˜ä¼°ç®—ç»“æœ
    result = {
        'training_config': {
            'task_name': task_name,
            'num_gpus': num_gpus,
            'gpu_ids': gpu_ids,
            'batch_size': batch_size
        },
        'memory_estimate': memory_estimate,
        'dataset_info': dataset_info,
        'resource_check': resource_check
    }
    
    with open('memory_estimate_result.json', 'w') as f:
        json.dump(result, f, indent=2, default=str)
    
    print(f"\nğŸ’¾ ä¼°ç®—ç»“æœå·²ä¿å­˜åˆ°: memory_estimate_result.json")

if __name__ == "__main__":
    main()
