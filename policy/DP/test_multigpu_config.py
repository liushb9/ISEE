#!/usr/bin/env python3
"""
æµ‹è¯•å¤šå¡è®­ç»ƒé…ç½®
éªŒè¯Fabricå®ä¾‹æ˜¯å¦æ­£ç¡®ä¼ é€’å’Œä½¿ç”¨
"""

import sys
import os
import torch

# æ·»åŠ è·¯å¾„
sys.path.append('/home/shengbang/RoboTwin/policy/DP')

def test_fabric_creation():
    """æµ‹è¯•Fabricå®ä¾‹åˆ›å»º"""
    print("=== æµ‹è¯•Fabricå®ä¾‹åˆ›å»º ===")
    
    try:
        from lightning.fabric import Fabric
        
        # åˆ›å»ºFabricå®ä¾‹
        fabric = Fabric(
            accelerator="cuda" if torch.cuda.is_available() else "cpu",
            devices=torch.cuda.device_count() if torch.cuda.is_available() else 1,
            strategy="ddp",
            precision="32-true",
        )
        
        print(f"âœ… Fabricå®ä¾‹åˆ›å»ºæˆåŠŸ")
        print(f"   åŠ é€Ÿå™¨: {fabric.accelerator}")
        print(f"   è®¾å¤‡æ•°é‡: {fabric.num_devices}")  # ä¿®å¤ï¼šä½¿ç”¨num_devices
        print(f"   ç­–ç•¥: {fabric.strategy}")
        print(f"   ç²¾åº¦: {fabric.precision}")
        
        return fabric
        
    except Exception as e:
        print(f"âŒ Fabricå®ä¾‹åˆ›å»ºå¤±è´¥: {e}")
        return None

def test_workspace_instantiation():
    """æµ‹è¯•workspaceå®ä¾‹åŒ–"""
    print("\n=== æµ‹è¯•Workspaceå®ä¾‹åŒ– ===")
    
    try:
        from diffusion_policy.workspace.robotworkspace import RobotWorkspace
        from omegaconf import OmegaConf
        
        # åˆ›å»ºå®Œæ•´çš„é…ç½®ç»“æ„ï¼Œæ»¡è¶³RobotWorkspaceåˆå§‹åŒ–éœ€æ±‚
        cfg = OmegaConf.create({
            "task": {
                "name": "test_task",
                "dataset": {
                    "_target_": "diffusion_policy.dataset.robot_image_dataset.RobotImageDataset",
                    "zarr_path": "data/test.zarr",
                    "horizon": 1,
                    "pad_before": 0,
                    "pad_after": 0,
                    "seed": 42,
                    "val_ratio": 0.0,
                    "batch_size": 1,
                    "max_train_episodes": None
                },
                "env_runner": None,
                "workspace": {
                    "_target_": "diffusion_policy.workspace.robotworkspace.RobotWorkspace"
                }
            },
            "policy": {
                "_target_": "diffusion_policy.policy.diffusion_unet_image_policy.DiffusionUnetImagePolicy",
                "obs_encoder": {
                    "_target_": "diffusion_policy.model.common.mlp.MLP",
                    "input_dim": 10,
                    "output_dim": 64,
                    "hidden_dims": [64, 64]
                },
                "action_dim": 10,
                "n_obs_steps": 2,
                "n_action_steps": 2,
                "n_cond_steps": 2,
                "horizon": 4,
                "obs_as_global_cond": True,
                "diffusion_step_embed_dim": 64,
                "down_dims": [64, 128, 256],
                "up_dims": [256, 128, 64],
                "n_groups": 8,
                "mid_blocks_per_group": 2,
                "use_fp16": False
            },
            "optimizer": {
                "_target_": "torch.optim.AdamW",
                "lr": 1e-4,
                "weight_decay": 1e-6
            },
            "dataloader": {
                "batch_size": 1,
                "num_workers": 0,
                "shuffle": True,
                "pin_memory": False,
                "persistent_workers": False
            },
            "val_dataloader": {
                "batch_size": 1,
                "num_workers": 0,
                "shuffle": False,
                "pin_memory": False,
                "persistent_workers": False
            },
            "training": {
                "seed": 42,
                "device": "cuda:0",
                "num_epochs": 1,
                "max_train_steps": None,
                "max_val_steps": None,
                "gradient_accumulate_every": 1,
                "lr_warmup_steps": 0,
                "lr_scheduler": "cosine",
                "checkpoint_every": 1,
                "val_every": 1,
                "sample_every": 1,
                "rollout_every": 1,
                "use_ema": False,
                "freeze_encoder": False,
                "debug": False,
                "resume": False,
                "tqdm_interval_sec": 0.1
            },
            "ema": {
                "_target_": "diffusion_policy.model.diffusion.ema_model.EMAModel",
                "decay": 0.9999
            },
            "checkpoint": {
                "topk": 5
            },
            "logging": {
                "mode": "disabled",
                "project": "test_project",
                "name": "test_run"
            },
            "head_camera_type": "default",
            "n_obs_steps": 2,
            "n_action_steps": 2,
            "horizon": 4,
            "obs_dim": 10,
            "action_dim": 10
        })
        
        print(f"âœ… é…ç½®åˆ›å»ºæˆåŠŸ")
        print(f"   é…ç½®é”®æ•°é‡: {len(cfg)}")
        
        # ç›´æ¥å®ä¾‹åŒ–RobotWorkspace
        workspace = RobotWorkspace(cfg)
        
        print(f"âœ… Workspaceå®ä¾‹åŒ–æˆåŠŸ")
        print(f"   ç±»å‹: {type(workspace)}")
        print(f"   Fabricå±æ€§: {hasattr(workspace, 'fabric')}")
        print(f"   Rankå±æ€§: {hasattr(workspace, 'rank')}")
        print(f"   World_sizeå±æ€§: {hasattr(workspace, 'world_size')}")
        
        return workspace
        
    except Exception as e:
        print(f"âŒ Workspaceå®ä¾‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def test_fabric_integration(fabric, workspace):
    """æµ‹è¯•Fabricä¸Workspaceçš„é›†æˆ"""
    print("\n=== æµ‹è¯•Fabricé›†æˆ ===")
    
    if fabric is None or workspace is None:
        print("âŒ æ— æ³•æµ‹è¯•é›†æˆï¼Œå®ä¾‹åˆ›å»ºå¤±è´¥")
        return
    
    try:
        # è®¾ç½®å¤šå¡è®­ç»ƒå±æ€§
        workspace.fabric = fabric
        workspace.rank = fabric.global_rank
        workspace.world_size = fabric.num_devices  # ä¿®å¤ï¼šä½¿ç”¨num_devices
        
        print(f"âœ… å¤šå¡è®­ç»ƒå±æ€§è®¾ç½®æˆåŠŸ")
        print(f"   Fabricå®ä¾‹: {workspace.fabric is not None}")
        print(f"   Rank: {workspace.rank}")
        print(f"   World_size: {workspace.world_size}")
        
        # æµ‹è¯•å¤šå¡è®­ç»ƒé€»è¾‘
        if hasattr(workspace, 'fabric') and workspace.fabric is not None:
            print(f"âœ… å¤šå¡è®­ç»ƒæ¨¡å¼æ£€æµ‹æˆåŠŸ")
        else:
            print(f"âŒ å¤šå¡è®­ç»ƒæ¨¡å¼æ£€æµ‹å¤±è´¥")
            
    except Exception as e:
        print(f"âŒ Fabricé›†æˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def test_device_management():
    """æµ‹è¯•è®¾å¤‡ç®¡ç†"""
    print("\n=== æµ‹è¯•è®¾å¤‡ç®¡ç† ===")
    
    try:
        from lightning.fabric import Fabric
        
        fabric = Fabric(
            accelerator="cuda" if torch.cuda.is_available() else "cpu",
            devices=torch.cuda.device_count() if torch.cuda.is_available() else 1,
            strategy="ddp",
        )
        
        device = fabric.device
        print(f"âœ… è®¾å¤‡ç®¡ç†æ­£å¸¸")
        print(f"   Fabricè®¾å¤‡: {device}")
        print(f"   CUDAå¯ç”¨: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"   GPUæ•°é‡: {torch.cuda.device_count()}")
            print(f"   å½“å‰GPU: {torch.cuda.current_device()}")
        
    except Exception as e:
        print(f"âŒ è®¾å¤‡ç®¡ç†æµ‹è¯•å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("=== å¤šå¡è®­ç»ƒé…ç½®æµ‹è¯• ===")
    
    # æµ‹è¯•Fabricåˆ›å»º
    fabric = test_fabric_creation()
    
    # æµ‹è¯•Workspaceå®ä¾‹åŒ–
    workspace = test_workspace_instantiation()
    
    # æµ‹è¯•é›†æˆ
    test_fabric_integration(fabric, workspace)
    
    # æµ‹è¯•è®¾å¤‡ç®¡ç†
    test_device_management()
    
    print("\nğŸ‰ æµ‹è¯•å®Œæˆ!")
    
    if fabric and workspace:
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Œå¤šå¡è®­ç»ƒé…ç½®æ­£å¸¸")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥é…ç½®")

if __name__ == "__main__":
    main()
